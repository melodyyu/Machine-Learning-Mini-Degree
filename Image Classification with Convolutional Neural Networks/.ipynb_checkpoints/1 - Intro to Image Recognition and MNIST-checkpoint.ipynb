{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics covered:\n",
    "- Intro to image recognition\n",
    "    - How machines process images\n",
    "    - Tools for image recognition\n",
    "- Intro to MNIST\n",
    "- Build, train and test a MNIST image recognition model \n",
    "- Build, train and test a MNIST image recognition model with Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Image Recognition\n",
    "**Image Recognition** : Seeing an object or image and knowing what it is.\n",
    "- How does it work for *humans*? \n",
    "    - In everyday life, we class everything into certain categories based on their attributes (i.e. recognizing an animal and classifying it based on its similarities to other species)\n",
    "    - Occurs subconsciously. We're able to attend to certain objects when we need to note them, but knowing what something is is based entirely on prvious experiences, deduction and memorization\n",
    "    - Items are separated due to border color differences (i.e distinguishing between foreground and background) <br> <br>\n",
    "- How does it work for *machines*?\n",
    "    - Only has knowledge of categories we have taught them and is only trained to separate objects into a few classifications (i.e facial recognition programs only classify images into faces or not faces)\n",
    "    - An image is an array of bytes. When processing an image, machines look at the values for each of the bytes and a corresponding pattern. This way, image recognition models look for groups of similar byte values across images to distinguish an image and classify it as such (i.e. high green and brown values may suggest an image contains a tree)\n",
    "        - Note: on a BW scale, 255 is black, 0 is white        \n",
    "    - Problems with processing images: \n",
    "        - Most images fed into simple models are small (MNIST images are 28x28 pixels, which is still difficult for the machine to process)\n",
    "        \n",
    "### How machines process images\n",
    "Machines process images by first breaking them into smaller parts and processing those instead. The machine's steps:\n",
    "- (1) Done in a **convolutional layer** in a neural network. Applies some kind of filter to different parts of the image to produce several smaller, distorted images composed of only a few pixels\n",
    "- (2) Makes the pieces more abstract by averaging together smaller squares of pixel values through a **max pooling layer** --> turns the images into something it may understand, but that humans may not \n",
    "\n",
    "### Definitions for processing images\n",
    "**convolution**: an operation on two functions to produce a third function that explains how the shape of one is modified by the other <br>\n",
    "**kernel**: a matrix used as a mask to image pixel values\n",
    "- often pre-determined through Tensorflow objects <br>\n",
    "\n",
    "\n",
    "**image convolution**: applying a kernel or convolution mask to blocks of pixels to apply the effect (like an Snapchat filter, but for the computer) \n",
    "- often used to blur or sharpen images or detect images <br>\n",
    "\n",
    "**max pooling**: replacing a block of pixels by one pixel with the highest value out of the block\n",
    "- helps to make an image more abstract\n",
    "- used to downsize an image and also prevent overfitting(drawing conclusions when there are none)\n",
    "- generally, we specify the matrix size and step size (number of pixels to step over) \n",
    "\n",
    "### How it all comes together\n",
    "Summary:\n",
    "- almost all convolutional neural networks have a convolutional layer followed by a max pooling layer\n",
    "- larger networks will repeat this one or more times along with other layers to perform additional processing\n",
    "- the result of the two layers is sa set of smaller, more abstract images comprised of parts of the original image\n",
    "- the purpose is to cut out unnecessary image noise and to focus on the stand-out features so that the model can focus on what's important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to MNIST\n",
    "**MNIST**: Modern National Institute of Standards of Technology. A dataset of images. \n",
    "- Images are divided into training images and testing images. \n",
    "- Each is a BW image of 28x28 pixels (784 total). Each is labelled based on which image it represents.\n",
    "- Each label is in one-hot encoding form (quantified way to encode categorical data. An array of 0s and 1s with 1s in the position that represent the digit and 0s in the rest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
